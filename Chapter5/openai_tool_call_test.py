# ç®€å•çš„OpenAIèŒƒå¼å·¥å…·è°ƒç”¨æµ‹è¯•
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv(override=True)

apiKey = os.getenv("LLM_API_KEY")
baseurl = os.getenv("LLM_BASE_URL")
model = os.getenv("LLM_MODEL_ID", "gpt-4o-mini")  # ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„æ¨¡å‹ï¼Œé»˜è®¤ä½¿ç”¨ gpt-4o-mini

# æ˜¾ç¤ºé…ç½®ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
print("ğŸ” å½“å‰é…ç½®:")
print(f"  API Key: {apiKey[:20]}..." if apiKey else "  API Key: æœªè®¾ç½®")
print(f"  Base URL: {baseurl}")
print(f"  æ¨¡å‹: {model}")
print()

if not apiKey or not baseurl:
    print("âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡")
    print("   è¯·ç¡®ä¿ .env æ–‡ä»¶ä¸­è®¾ç½®äº† LLM_API_KEY å’Œ LLM_BASE_URL")
    exit(1)

client = OpenAI(api_key=apiKey, base_url=baseurl)

tools = [
  {
    "type": "function", #å·¥å…·ç±»å‹
    "function": {
      "name": "get_current_weather", #å‡½æ•°åç§°
      "description": "Get the current weather in a given location", #å‡½æ•°æè¿°
      "parameters": { #å‡½æ•°å‚æ•°
        "type": "object", #å‚æ•°ç±»å‹
        "properties": { #å‚æ•°å±æ€§
          "location": {"type": "string", "description": "The city and state, e.g. San Francisco, CA"}, #å‚æ•°åç§°å’Œæè¿°
          "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}, #å‚æ•°æšä¸¾å€¼
        },
        "required": ["location"], #å‚æ•°å¿…å¡«
      },
    }
  }
]

messages = [
    {"role":"user","content":"What's the weather like in Boston today?"}
]

# å…ˆæµ‹è¯•ä¸å¸¦å·¥å…·è°ƒç”¨çš„æ™®é€šå¯¹è¯ï¼ˆç¡®è®¤ä»£ç†æœåŠ¡å¯ç”¨ï¼‰
print("ğŸ“ æ­¥éª¤1: æµ‹è¯•åŸºç¡€å¯¹è¯åŠŸèƒ½ï¼ˆä¸å¸¦å·¥å…·è°ƒç”¨ï¼‰...")
try:
    test_completion = client.chat.completions.create(
        model=model,  # ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„æ¨¡å‹
        messages=[{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•å›å¤"}],
    )
    print("âœ… åŸºç¡€å¯¹è¯æµ‹è¯•æˆåŠŸï¼Œä»£ç†æœåŠ¡å¯ç”¨")
    print()
except Exception as e:
    print(f"âŒ åŸºç¡€å¯¹è¯æµ‹è¯•å¤±è´¥: {e}")
    print("   è¿™è¯´æ˜ä»£ç†æœåŠ¡æœ¬èº«å¯èƒ½æœ‰é—®é¢˜ï¼Œè¯·å…ˆè§£å†³åŸºç¡€è¿æ¥é—®é¢˜")
    print(f"   å½“å‰ä½¿ç”¨çš„æ¨¡å‹: {model}")
    print("   æç¤º: å¦‚æœæ¨¡å‹åç§°ä¸æ­£ç¡®ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ LLM_MODEL_ID")
    print()
    exit(1)

# æµ‹è¯•å·¥å…·è°ƒç”¨åŠŸèƒ½
print("ğŸ“ æ­¥éª¤2: æµ‹è¯•å·¥å…·è°ƒç”¨åŠŸèƒ½...")
try:
    print("ğŸš€ æ­£åœ¨è°ƒç”¨ APIï¼ˆå¸¦å·¥å…·è°ƒç”¨ï¼‰...")
    print(f"   æ¨¡å‹: {model}")
    print(f"   å·¥å…·æ•°é‡: {len(tools)}")
    print()
    
    completion = client.chat.completions.create(
        model=model,  # ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„æ¨¡å‹
        messages=messages,
        tools=tools,
        tool_choice="auto",
    )
    
    print("âœ… API è°ƒç”¨æˆåŠŸ!")
    
    message = completion.choices[0].message
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    if message.tool_calls:
        print("\n" + "="*70)
        print("ğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼ï¼‰")
        print("="*70)
        print("\nğŸ’¡ ä¸ºä»€ä¹ˆ content ä¸ºç©ºï¼Ÿ")
        print("   å½“æ¨¡å‹å†³å®šè°ƒç”¨å·¥å…·æ—¶ï¼Œå®ƒä¸ä¼šç”Ÿæˆæ–‡æœ¬å†…å®¹ï¼Œè€Œæ˜¯è¿”å›å·¥å…·è°ƒç”¨è¯·æ±‚ã€‚")
        print("   è¿™æ˜¯ OpenAI Function Calling çš„æ­£å¸¸è¡Œä¸ºã€‚")
        print()
        print("ğŸ“‹ å·¥å…·è°ƒç”¨è¯¦æƒ…:")
        for tool_call in message.tool_calls:
            print(f"  - å·¥å…·åç§°: {tool_call.function.name}")
            print(f"  - å‚æ•°: {tool_call.function.arguments}")
            print(f"  - è°ƒç”¨ID: {tool_call.id}")
        print()
        
        # å°†åŠ©æ‰‹çš„æ¶ˆæ¯ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ï¼‰æ·»åŠ åˆ°æ¶ˆæ¯å†å²
        messages.append(message)
        
        # æ¨¡æ‹Ÿæ‰§è¡Œå·¥å…·å¹¶è¿”å›ç»“æœ
        print("ğŸ”¨ æ­¥éª¤3: æ‰§è¡Œå·¥å…·å¹¶è·å–ç»“æœ...")
        tool_results = []
        for tool_call in message.tool_calls:
            tool_name = tool_call.function.name
            import json
            tool_args = json.loads(tool_call.function.arguments)
            
            print(f"   æ‰§è¡Œå·¥å…·: {tool_name}")
            print(f"   å‚æ•°: {tool_args}")
            
            # æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œï¼ˆå®é™…åº”è¯¥è°ƒç”¨çœŸå®çš„å·¥å…·å‡½æ•°ï¼‰
            if tool_name == "get_current_weather":
                location = tool_args.get("location", "æœªçŸ¥")
                unit = tool_args.get("unit", "celsius")
                # æ¨¡æ‹Ÿå¤©æ°”æ•°æ®
                weather_result = f"æ³¢å£«é¡¿ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ¸©åº¦ 22Â°{unit[0].upper()}"
                tool_results.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": tool_name,
                    "content": weather_result
                })
                print(f"   ç»“æœ: {weather_result}")
        
        # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
        messages.extend(tool_results)
        
        # å†æ¬¡è°ƒç”¨ APIï¼Œè®©æ¨¡å‹åŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        print("\nğŸ”„ æ­¥éª¤4: åŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...")
        final_completion = client.chat.completions.create(
            model=model,
            messages=messages,
            tools=tools,  # ä»ç„¶æä¾›å·¥å…·ï¼Œä½†æ¨¡å‹å¯èƒ½ä¸å†éœ€è¦è°ƒç”¨
        )
        
        final_message = final_completion.choices[0].message
        print("âœ… è·å¾—æœ€ç»ˆç­”æ¡ˆ!")
        print("\n" + "="*70)
        print("ğŸ’¬ æœ€ç»ˆå›å¤:")
        print("="*70)
        print(final_message.content)
        print("="*70)
        
    else:
        print("\nğŸ’¬ æ¨¡å‹ç›´æ¥å›å¤ï¼ˆæœªä½¿ç”¨å·¥å…·ï¼‰:")
        print(message.content if message.content else "(ç©ºå†…å®¹)")
        

except Exception as e:
    error_msg = str(e)
    print(f"\nâŒ API è°ƒç”¨å¤±è´¥: {error_msg}")
    
    if "unsupported_country_region_territory" in error_msg or "403" in error_msg:
        print("\n" + "="*70)
        print("ğŸ” é—®é¢˜è¯Šæ–­: å³ä½¿ä½¿ç”¨äº†åå‘ä»£ç†ï¼Œä»ç„¶é‡åˆ°åœ°åŒºé™åˆ¶")
        print("="*70)
        print("\nå¯èƒ½çš„åŸå› :")
        print("1. âŒ åå‘ä»£ç†æœåŠ¡æœ¬èº«ä¸æ”¯æŒå·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰")
        print("   - æŸäº›ä»£ç†æœåŠ¡åªæ”¯æŒåŸºç¡€çš„èŠå¤©åŠŸèƒ½ï¼Œä¸æ”¯æŒ tools å‚æ•°")
        print("   - éœ€è¦ç¡®è®¤ä½ çš„ä»£ç†æœåŠ¡æ˜¯å¦æ”¯æŒ OpenAI Function Calling")
        print()
        print("2. âŒ åå‘ä»£ç†æœåŠ¡é…ç½®é—®é¢˜")
        print("   - ä»£ç†æœåŠ¡å¯èƒ½æ²¡æœ‰æ­£ç¡®è½¬å‘ tools å‚æ•°")
        print("   - æˆ–è€…ä»£ç†æœåŠ¡å¯¹å·¥å…·è°ƒç”¨æœ‰ç‰¹æ®Šé™åˆ¶")
        print()
        print("3. âŒ æ¨¡å‹åç§°é—®é¢˜")
        print(f"   - å½“å‰ä½¿ç”¨: '{model}'")
        print("   - æŸäº›ä»£ç†æœåŠ¡å¯èƒ½éœ€è¦ä¸åŒçš„æ¨¡å‹åç§°æ ¼å¼")
        print("   - å»ºè®®å°è¯•: 'gpt-4o', 'gpt-4o-mini', 'gpt-4', 'gpt-3.5-turbo' ç­‰")
        print("   - æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ LLM_MODEL_ID è®¾ç½®")
        print()
        print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("1. ç¡®è®¤ä»£ç†æœåŠ¡æ”¯æŒ Function Calling")
        print("   - æŸ¥çœ‹ä»£ç†æœåŠ¡çš„æ–‡æ¡£")
        print("   - è”ç³»ä»£ç†æœåŠ¡æä¾›å•†ç¡®è®¤")
        print()
        print("2. å°è¯•ä¸åŒçš„æ¨¡å‹åç§°")
        print(f"   - å½“å‰æ¨¡å‹: '{model}'")
        print("   - åœ¨ .env æ–‡ä»¶ä¸­ä¿®æ”¹ LLM_MODEL_ID")
        print("   - æˆ–ä½¿ç”¨ä»£ç†æœåŠ¡æ¨èçš„æ¨¡å‹åç§°ï¼ˆå¦‚ 'gpt-4o'ï¼‰")
        print()
        print("3. ä½¿ç”¨æ”¯æŒå·¥å…·è°ƒç”¨çš„å…¶ä»–æœåŠ¡")
        print("   - DeepSeek API (æ”¯æŒ Function Calling)")
        print("   - é€šä¹‰åƒé—® API (æ”¯æŒ Function Calling)")
        print()
        print("4. æµ‹è¯•ä»£ç†æœåŠ¡æ˜¯å¦æ”¯æŒå·¥å…·è°ƒç”¨")
        print("   å¯ä»¥å…ˆæµ‹è¯•ä¸å¸¦ tools å‚æ•°çš„æ™®é€šå¯¹è¯ï¼Œç¡®è®¤ä»£ç†å¯ç”¨")
        print("   ç„¶åå†æµ‹è¯•å¸¦ tools å‚æ•°çš„è°ƒç”¨")
        print("="*70)
    else:
        print(f"\nå…¶ä»–é”™è¯¯ç±»å‹: {type(e).__name__}")
        print("\nè¯·æ£€æŸ¥:")
        print("1. API Key æ˜¯å¦æ­£ç¡®")
        print("2. Base URL æ˜¯å¦æ­£ç¡®ï¼ˆæ˜¯å¦åŒ…å« /v1 åç¼€ï¼‰")
        print("3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("4. ä»£ç†æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")